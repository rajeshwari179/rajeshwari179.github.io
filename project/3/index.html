<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/rajeshwari179.github.io/_next/static/media/c9a5bc6a7c948fb0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/rajeshwari179.github.io/_next/static/css/e0b7e5d5ffdc86c6.css" data-precedence="next"/><link rel="stylesheet" href="/rajeshwari179.github.io/_next/static/css/3cc226f0877344cc.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/rajeshwari179.github.io/_next/static/chunks/webpack-6238dfa248d38f1e.js"/><script src="/rajeshwari179.github.io/_next/static/chunks/fd9d1056-cb422f7581ecfa2f.js" async=""></script><script src="/rajeshwari179.github.io/_next/static/chunks/23-75e956f4d16d7bd4.js" async=""></script><script src="/rajeshwari179.github.io/_next/static/chunks/main-app-eb2e0dafa72a0a0f.js" async=""></script><script src="/rajeshwari179.github.io/_next/static/chunks/173-45ae19e0432c0727.js" async=""></script><script src="/rajeshwari179.github.io/_next/static/chunks/app/project/3/page-f1c5332e455f85bf.js" async=""></script><script src="/rajeshwari179.github.io/_next/static/chunks/231-af777def82264613.js" async=""></script><script src="/rajeshwari179.github.io/_next/static/chunks/app/layout-7513d9a03965dc6e.js" async=""></script><title>Create Next App</title><meta name="description" content="Generated by create next app"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><meta name="next-size-adjust"/><script src="/rajeshwari179.github.io/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_ae7d09"><div id="title" class="title"></div><div id="navbar" class="Navbar_navbar__fk_p7"><p class="Navbar_inactive__I_vRp"><a href="/">Home</a></p><p class="Navbar_inactive__I_vRp"><a href="/about/">Experience</a></p><p class="Navbar_inactive__I_vRp"><a href="/project/">Projects</a></p><p class="Navbar_inactive__I_vRp"><a href="/designs/">Designs</a></p></div><div style="border:2px solid #000;padding:20px;border-radius:10px"><h1>Clustering with Contrastive Learning</h1><div class="ProjectTemplate_box__pk1Aa"><div style="flex:1"><div class="ProjectTemplate_descriptionContainer__g40_B"><h2>Introduction</h2><p class="ProjectTemplate_projectDescription__RSofK">Unsupervised clustering seeks to identify meaningful groups in data based on distances within a representation space. However, the initial overlap of distinct categories in the representation space presents a considerable challenge for achieving clear separation in distance-based clustering. Unsupervised learning faces a fundamental challenge in clustering, a topic extensively explored for many years. Traditional clustering methods like K-means and Gaussian Mixture Models rely on distance metrics in the data space, proving less effective for high-dimensional data. Our class discussions highlighted the sensitivity of K-means to initial centroids, as depicted in Figure 1, where it struggles to cluster accurately. In contrast, there is a growing interest in leveraging deep neural networks to map data into a lower-dimensional, more distinguishable representation space. To address these challenges, we introduce Supporting Clustering with Contrastive Learning (SCCL), a novel approach that optimizes both top-down clustering loss and bottom-up instance- wise contrastive loss concurrently. Our evaluation focuses on the increasingly crucial task of short text clustering. Through detailed analysis, we illustrate how SCCL successfully combines top-down clustering with bottom-up instance-wise contrastive learning, resulting in improved inter-cluster and intra-cluster distances. Figure 1: Failure of K-means.<ul><li>This project is the implemenetation of the paper &quot;Supporting Clustering with Contrastive Learning&quot;</li></ul></p></div></div><div class="ProjectTemplate_imageSection__fIgKC"><div class="ProjectTemplate_imageContainer__Xmpvw"><div class="ProjectTemplate_customImage__wSvfz"><img alt="Project Introduction" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" sizes="100vw" srcSet="/_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl1.efe3e256.png&amp;w=640&amp;q=75 640w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl1.efe3e256.png&amp;w=750&amp;q=75 750w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl1.efe3e256.png&amp;w=828&amp;q=75 828w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl1.efe3e256.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl1.efe3e256.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl1.efe3e256.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl1.efe3e256.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl1.efe3e256.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl1.efe3e256.png&amp;w=3840&amp;q=75"/></div></div><p class="ProjectTemplate_imageDescription__B6C1V">Figure 1:TSNE visualization of the embedding space learned on SearchSnippets</p></div></div><div class="ProjectTemplate_box__pk1Aa"><div style="flex:1"><div class="ProjectTemplate_descriptionContainer__g40_B"><h2>Experimental Setup</h2><p class="ProjectTemplate_projectDescription__RSofK">We aim at developing a joint model that leverages the beneficial properties of Instance-CL to improve unsupervised clustering. As illustrated in Figure 2, our model consists of three components. A neural network ψ(·) first maps the input data to the representation space, which is then followed by two different heads g(·) and f (·) where the contrastive loss and the clustering loss are applied, respectively. Our data consists of both the original and the augmented data. Specifically, for a randomly sampled minibatch B of size M,  we randomly generate a pair of augmentations for each data instance in B, yielding an augmented batch B&#x27; with size 2M<ul><li>Topics: The dataset comprises four distinct topics</li><li>Number of Clusters (K): K-means and SCCL are both configured with K = 4</li><li>Sentence Transformers: We utilize BERT-based Sentence Transformers for feature extraction and representation</li><li>Text Augmenter: NLP Augmenter is employed for data augmentation</li><li>Training Data: The training dataset consists of 10,000 short text samples</li><li>System Used: 2 GPU node on PACE ICE cluster</li></ul>The evaluation metric used to measure the performance of the clustering algorithms is accuracy.</p></div></div><div class="ProjectTemplate_imageSection__fIgKC"><div class="ProjectTemplate_imageContainer__Xmpvw"><div class="ProjectTemplate_customImage__wSvfz"><img alt="Project Experimental Setup" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" sizes="100vw" srcSet="/_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl2.265ccee4.png&amp;w=640&amp;q=75 640w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl2.265ccee4.png&amp;w=750&amp;q=75 750w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl2.265ccee4.png&amp;w=828&amp;q=75 828w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl2.265ccee4.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl2.265ccee4.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl2.265ccee4.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl2.265ccee4.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl2.265ccee4.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl2.265ccee4.png&amp;w=3840&amp;q=75"/></div></div><p class="ProjectTemplate_imageDescription__B6C1V">Figure 2:Training framework SCCL</p></div></div><div class="ProjectTemplate_box__pk1Aa"><div style="flex:1"><div class="ProjectTemplate_descriptionContainer__g40_B"><h2>Inferences</h2><p class="ProjectTemplate_projectDescription__RSofK">CL, we monitor both intra- cluster distance and inter-cluster distance in the representation space throughout the learning process. In the context of a specific cluster, intra-cluster distance refers to the average distance between the centroid and all samples within that cluster, while inter-cluster distance is the distance to the nearest neighboring cluster. In Figure, we present each distance type along with its mean value obtained by averaging across all clusters. Clusters are defined either based on ground truth labels (solid line). Figure 3 illustrates that Clustering achieves a smaller intra-cluster distance and a larger inter-cluster distance when evaluated on predicted clusters. This highlights Clustering&#x27;s capability to tighten each self-learned cluster and separate different clusters effectively. However, when evaluated on ground truth clusters, along with poor Accuracy and NMI scores, we observe the opposite trend. One possible explanation is that data from different ground-truth clusters often exhibit significant overlap in the embedding space before clustering begins making it challenging for our distance-based clustering approach to effectively separate them</p></div></div><div class="ProjectTemplate_imageSection__fIgKC"><div class="ProjectTemplate_imageContainer__Xmpvw"><div class="ProjectTemplate_customImage__wSvfz"><img alt="Project Inferences" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" sizes="100vw" srcSet="/_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl3.27606eeb.png&amp;w=640&amp;q=75 640w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl3.27606eeb.png&amp;w=750&amp;q=75 750w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl3.27606eeb.png&amp;w=828&amp;q=75 828w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl3.27606eeb.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl3.27606eeb.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl3.27606eeb.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl3.27606eeb.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl3.27606eeb.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=%2Frajeshwari179.github.io%2F%2F_next%2Fstatic%2Fmedia%2Fsccl3.27606eeb.png&amp;w=3840&amp;q=75"/></div></div><p class="ProjectTemplate_imageDescription__B6C1V">Figure 3: Cluster-level evaluation on SearchSnippets. Each plot is summarized over five random runs</p></div></div></div><script src="/rajeshwari179.github.io/_next/static/chunks/webpack-6238dfa248d38f1e.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/rajeshwari179.github.io/_next/static/media/c9a5bc6a7c948fb0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/rajeshwari179.github.io/_next/static/css/e0b7e5d5ffdc86c6.css\",\"style\"]\n3:HL[\"/rajeshwari179.github.io/_next/static/css/3cc226f0877344cc.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"4:I[5751,[],\"\"]\n7:I[8173,[\"173\",\"static/chunks/173-45ae19e0432c0727.js\",\"198\",\"static/chunks/app/project/3/page-f1c5332e455f85bf.js\"],\"Image\"]\n9:I[9275,[],\"\"]\na:I[1343,[],\"\"]\nb:I[3462,[\"231\",\"static/chunks/231-af777def82264613.js\",\"185\",\"static/chunks/app/layout-7513d9a03965dc6e.js\"],\"default\"]\nd:I[6130,[],\"\"]\n6:T589,Unsupervised clustering seeks to identify meaningful groups in data based on distances within a representation space. However, the initial overlap of distinct categories in the representation space presents a considerable challenge for achieving clear separation in distance-based clustering. Unsupervised learning faces a fundamental challenge in clustering, a topic extensively explored for many years. Traditional clustering methods like K-means and Gaussian Mixture Models rely on distance metrics in the data space, proving less effective for high-dimensional data. Our class discussions highlighted the sensitivity of K-means to initial centroids, as depicted in Figure 1, where it struggles to cluster accurately. In contrast, there is a growing interest in leveraging deep neural networks to map data into a lower-dimensional, more distinguishable representation space. To address these challenges, we introduce Supporting Clustering with Contrastive Learning (SCCL), a novel approach that optimizes both top-down clustering loss and bottom-up instance- wise contrastive loss concurrently. Our evaluation focuses on the increasingly crucial task of short text clustering. Through detailed analysis, we illustrate how SCCL successfully combines top-down clustering with bottom-up instance-wise contrastive learning, resulting in improved inter-cluster and intra-cluster distances. Figure 1: Failure of K-means.8:T4a7,CL, we monitor both intra- cluster distance and inter-cluster distance in the representation space throughout the learning process. In the context of a specific cluster, intra-cluster distance refers to the average distance between the centroid and all samples within that cluster, while inter-cluster dis"])</script><script>self.__next_f.push([1,"tance is the distance to the nearest neighboring cluster. In Figure, we present each distance type along with its mean value obtained by averaging across all clusters. Clusters are defined either based on ground truth labels (solid line). Figure 3 illustrates that Clustering achieves a smaller intra-cluster distance and a larger inter-cluster distance when evaluated on predicted clusters. This highlights Clustering's capability to tighten each self-learned cluster and separate different clusters effectively. However, when evaluated on ground truth clusters, along with poor Accuracy and NMI scores, we observe the opposite trend. One possible explanation is that data from different ground-truth clusters often exhibit significant overlap in the embedding space before clustering begins making it challenging for our distance-based clustering approach to effectively separate theme:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/rajeshwari179.github.io/_next/static/css/e0b7e5d5ffdc86c6.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L4\",null,{\"buildId\":\"rw08EXohAM_7HdnG9emRL\",\"assetPrefix\":\"/rajeshwari179.github.io\",\"initialCanonicalUrl\":\"/project/3/\",\"initialTree\":[\"\",{\"children\":[\"project\",{\"children\":[\"3\",{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"project\",{\"children\":[\"3\",{\"children\":[\"__PAGE__\",{},[[\"$L5\",[\"$\",\"div\",null,{\"style\":{\"border\":\"2px solid #000\",\"padding\":\"20px\",\"borderRadius\":\"10px\"},\"children\":[[\"$\",\"h1\",null,{\"children\":\"Clustering with Contrastive Learning\"}],[[\"$\",\"div\",null,{\"className\":\"ProjectTemplate_box__pk1Aa\",\"children\":[[\"$\",\"div\",null,{\"style\":{\"flex\":1},\"children\":[\"$\",\"div\",null,{\"className\":\"ProjectTemplate_descriptionContainer__g40_B\",\"children\":[[\"$\",\"h2\",null,{\"children\":\"Introduction\"}],[\"$\",\"p\",null,{\"className\":\"ProjectTemplate_projectDescription__RSofK\",\"children\":[\"$6\",[\"$\",\"ul\",null,{\"children\":[\"$\",\"li\",null,{\"children\":\"This project is the implemenetation of the paper \\\"Supporting Clustering with Contrastive Learning\\\"\"}]}]]}]]}]}],[\"$\",\"div\",null,{\"className\":\"ProjectTemplate_imageSection__fIgKC\",\"children\":[[\"$\",\"div\",null,{\"className\":\"ProjectTemplate_imageContainer__Xmpvw\",\"children\":[\"$\",\"div\",null,{\"className\":\"ProjectTemplate_customImage__wSvfz\",\"children\":[\"$\",\"$L7\",null,{\"src\":{\"src\":\"/rajeshwari179.github.io//_next/static/media/sccl1.efe3e256.png\",\"height\":726,\"width\":1424,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAECAIAAAA8r+mnAAAAWklEQVR42gUAWxJAILD7384nhg8zSpQe2/baimG9kfYSABq1Usi9GEKiRkwF4Peht7lSjBCkfKSyBTLjl1mmk6sVs0XNhd2FP7OJjGrx6F2CPr6K0Tgt8Blj/K1IWm/u9S/qAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":4},\"alt\":\"Project Introduction\",\"layout\":\"fill\"}]}]}],[\"$\",\"p\",null,{\"className\":\"ProjectTemplate_imageDescription__B6C1V\",\"children\":\"Figure 1:TSNE visualization of the embedding space learned on SearchSnippets\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"ProjectTemplate_box__pk1Aa\",\"children\":[[\"$\",\"div\",null,{\"style\":{\"flex\":1},\"children\":[\"$\",\"div\",null,{\"className\":\"ProjectTemplate_descriptionContainer__g40_B\",\"children\":[[\"$\",\"h2\",null,{\"children\":\"Experimental Setup\"}],[\"$\",\"p\",null,{\"className\":\"ProjectTemplate_projectDescription__RSofK\",\"children\":[\"We aim at developing a joint model that leverages the beneficial properties of Instance-CL to improve unsupervised clustering. As illustrated in Figure 2, our model consists of three components. A neural network ψ(·) first maps the input data to the representation space, which is then followed by two different heads g(·) and f (·) where the contrastive loss and the clustering loss are applied, respectively. Our data consists of both the original and the augmented data. Specifically, for a randomly sampled minibatch B of size M,  we randomly generate a pair of augmentations for each data instance in B, yielding an augmented batch B' with size 2M\",[\"$\",\"ul\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":\"Topics: The dataset comprises four distinct topics\"}],[\"$\",\"li\",null,{\"children\":\"Number of Clusters (K): K-means and SCCL are both configured with K = 4\"}],[\"$\",\"li\",null,{\"children\":\"Sentence Transformers: We utilize BERT-based Sentence Transformers for feature extraction and representation\"}],[\"$\",\"li\",null,{\"children\":\"Text Augmenter: NLP Augmenter is employed for data augmentation\"}],[\"$\",\"li\",null,{\"children\":\"Training Data: The training dataset consists of 10,000 short text samples\"}],[\"$\",\"li\",null,{\"children\":\"System Used: 2 GPU node on PACE ICE cluster\"}]]}],\"The evaluation metric used to measure the performance of the clustering algorithms is accuracy.\"]}]]}]}],[\"$\",\"div\",null,{\"className\":\"ProjectTemplate_imageSection__fIgKC\",\"children\":[[\"$\",\"div\",null,{\"className\":\"ProjectTemplate_imageContainer__Xmpvw\",\"children\":[\"$\",\"div\",null,{\"className\":\"ProjectTemplate_customImage__wSvfz\",\"children\":[\"$\",\"$L7\",null,{\"src\":{\"src\":\"/rajeshwari179.github.io//_next/static/media/sccl2.265ccee4.png\",\"height\":548,\"width\":1752,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAADCAIAAAAhqtkfAAAAUUlEQVR42gUAMQqAIND/v6NPNAXtIVRDg6NClJV2et6dCaGkNiT5Wss5V5EXZZj3yVwKU7q9FyZrrXMuPmHRq9mMYkwEUagAQCHmcB5jF3T/A9vuQlXB/wgoAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":3},\"alt\":\"Project Experimental Setup\",\"layout\":\"fill\"}]}]}],[\"$\",\"p\",null,{\"className\":\"ProjectTemplate_imageDescription__B6C1V\",\"children\":\"Figure 2:Training framework SCCL\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"ProjectTemplate_box__pk1Aa\",\"children\":[[\"$\",\"div\",null,{\"style\":{\"flex\":1},\"children\":[\"$\",\"div\",null,{\"className\":\"ProjectTemplate_descriptionContainer__g40_B\",\"children\":[[\"$\",\"h2\",null,{\"children\":\"Inferences\"}],[\"$\",\"p\",null,{\"className\":\"ProjectTemplate_projectDescription__RSofK\",\"children\":\"$8\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"ProjectTemplate_imageSection__fIgKC\",\"children\":[[\"$\",\"div\",null,{\"className\":\"ProjectTemplate_imageContainer__Xmpvw\",\"children\":[\"$\",\"div\",null,{\"className\":\"ProjectTemplate_customImage__wSvfz\",\"children\":[\"$\",\"$L7\",null,{\"src\":{\"src\":\"/rajeshwari179.github.io//_next/static/media/sccl3.27606eeb.png\",\"height\":918,\"width\":1072,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAHCAIAAAC6O5sJAAAAdUlEQVR42iWNCwrDMAxDc/+bDkYT/2Uno3M3kI1AT2jc9+1mpvI5OzOFuQXkEJV1vSAcKgDOOWJGKqOJpXbpetNUUxKevPqPqgLqT/3a7+DlNJ8gnEMmlDIBGELh8mw0jjwe2V49UKdv1N7mQSTIbEWEu++qL/p/oQgxtk3rAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":7},\"alt\":\"Project Inferences\",\"layout\":\"fill\"}]}]}],[\"$\",\"p\",null,{\"className\":\"ProjectTemplate_imageDescription__B6C1V\",\"children\":\"Figure 3: Cluster-level evaluation on SearchSnippets. Each plot is summarized over five random runs\"}]]}]]}]]]}]],null],null]},[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"project\",\"children\",\"3\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/rajeshwari179.github.io/_next/static/css/3cc226f0877344cc.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]}],null]},[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"project\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_ae7d09\",\"children\":[[\"$\",\"div\",null,{\"id\":\"title\",\"className\":\"title\"}],[\"$\",\"$Lb\",null,{}],[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}]]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[false,\"$Lc\"],\"globalErrorComponent\":\"$d\",\"missingSlots\":\"$We\"}]]\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Create Next App\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Generated by create next app\"}],[\"$\",\"link\",\"4\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"meta\",\"5\",{\"name\":\"next-size-adjust\"}]]\n5:null\n"])</script></body></html>